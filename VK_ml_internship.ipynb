{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "from urllib.parse import urlencode\n",
        "from tqdm import tqdm\n",
        "\n",
        "links = [\n",
        "    \"https://disk.yandex.ru/d/PEOGKbj5qJmGlQ\",\n",
        "    \"https://disk.yandex.ru/d/1sqxBbA1hRumDQ\",\n",
        "    \"https://disk.yandex.ru/d/Be8jLxVcQZ70lQ\",\n",
        "]\n",
        "\n",
        "filenames = [\n",
        "    \"labels_json.zip\",\n",
        "    \"data_train_short.zip\",\n",
        "    \"data_test_short.zip\",\n",
        "]\n",
        "\n",
        "actual_links = []\n",
        "for link in links:\n",
        "    base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
        "    final_url = base_url + urlencode(dict(public_key=link))\n",
        "    response = requests.get(final_url)\n",
        "    actual_links.append(response.json()['href'])\n",
        "\n",
        "for filename,link in zip(filenames, actual_links):\n",
        "    response = requests.get(link, stream=True)\n",
        "    file_size = int(response.headers.get(\"Content-Length\", 0))\n",
        "    chunk_size = 1024 * 1024\n",
        "\n",
        "    with tqdm(total=file_size, unit=\"B\", unit_scale=True, desc=\"Скачивание\") as pbar:\n",
        "        with open(filename, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=chunk_size):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "                    pbar.update(len(chunk))\n",
        "\n",
        "    print(f\"Файл '{filename}' успешно скачан.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_pQ1_ZK9wQI",
        "outputId": "91f28bbd-3582-4eb7-923e-090f35825e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Скачивание: 100%|██████████| 4.34k/4.34k [00:00<00:00, 1.83MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл 'labels_json.zip' успешно скачан.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Скачивание: 100%|██████████| 20.0G/20.0G [17:54<00:00, 18.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл 'data_train_short.zip' успешно скачан.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Скачивание: 100%|██████████| 12.9G/12.9G [12:35<00:00, 17.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл 'data_test_short.zip' успешно скачан.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/labels_json.zip\n",
        "!unzip /content/data_train_short.zip\n",
        "!unzip /content/data_test_short.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvrTF27aBUam",
        "outputId": "2562d50f-cf14-45f6-9d1f-c34637af80e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/labels_json.zip\n",
            "  inflating: labels_json/test_labels.json  \n",
            "  inflating: labels_json/train_labels.json  \n",
            "Archive:  /content/data_train_short.zip\n",
            "   creating: data_train_short/\n",
            "   creating: data_train_short/-220020068_456255414/\n",
            "  inflating: data_train_short/-220020068_456255414/-220020068_456255414.mp4  \n",
            "   creating: data_train_short/-220020068_456249693/\n",
            "  inflating: data_train_short/-220020068_456249693/-220020068_456249693.mp4  \n",
            "   creating: data_train_short/-220020068_456255339/\n",
            "  inflating: data_train_short/-220020068_456255339/-220020068_456255339.mp4  \n",
            "   creating: data_train_short/-220020068_456241755/\n",
            "  inflating: data_train_short/-220020068_456241755/-220020068_456241755.mp4  \n",
            "   creating: data_train_short/-220020068_456241671/\n",
            "  inflating: data_train_short/-220020068_456241671/-220020068_456241671.mp4  \n",
            "   creating: data_train_short/-220020068_456255340/\n",
            "  inflating: data_train_short/-220020068_456255340/-220020068_456255340.mp4  \n",
            "   creating: data_train_short/-220020068_456241756/\n",
            "  inflating: data_train_short/-220020068_456241756/-220020068_456241756.mp4  \n",
            "   creating: data_train_short/-220020068_456256016/\n",
            "  inflating: data_train_short/-220020068_456256016/-220020068_456256016.mp4  \n",
            "   creating: data_train_short/-220020068_456249732/\n",
            "  inflating: data_train_short/-220020068_456249732/-220020068_456249732.mp4  \n",
            "   creating: data_train_short/-220020068_456255332/\n",
            "  inflating: data_train_short/-220020068_456255332/-220020068_456255332.mp4  \n",
            "   creating: data_train_short/-220020068_456241672/\n",
            "  inflating: data_train_short/-220020068_456241672/-220020068_456241672.mp4  \n",
            "   creating: data_train_short/-220020068_456255341/\n",
            "  inflating: data_train_short/-220020068_456255341/-220020068_456255341.mp4  \n",
            "   creating: data_train_short/-220020068_456256475/\n",
            "  inflating: data_train_short/-220020068_456256475/-220020068_456256475.mp4  \n",
            "   creating: data_train_short/-220020068_456256013/\n",
            "  inflating: data_train_short/-220020068_456256013/-220020068_456256013.mp4  \n",
            "   creating: data_train_short/-220020068_456248657/\n",
            "  inflating: data_train_short/-220020068_456248657/-220020068_456248657.mp4  \n",
            "   creating: data_train_short/-220020068_456241673/\n",
            "  inflating: data_train_short/-220020068_456241673/-220020068_456241673.mp4  \n",
            "   creating: data_train_short/-220020068_456255402/\n",
            "  inflating: data_train_short/-220020068_456255402/-220020068_456255402.mp4  \n",
            "   creating: data_train_short/-220020068_456257139/\n",
            "  inflating: data_train_short/-220020068_456257139/-220020068_456257139.mp4  \n",
            "   creating: data_train_short/-220020068_456254621/\n",
            "  inflating: data_train_short/-220020068_456254621/-220020068_456254621.mp4  \n",
            "   creating: data_train_short/-220020068_456241758/\n",
            "  inflating: data_train_short/-220020068_456241758/-220020068_456241758.mp4  \n",
            "   creating: data_train_short/-220020068_456252055/\n",
            "  inflating: data_train_short/-220020068_456252055/-220020068_456252055.mp4  \n",
            "   creating: data_train_short/-220020068_456249739/\n",
            "  inflating: data_train_short/-220020068_456249739/-220020068_456249739.mp4  \n",
            "   creating: data_train_short/-220020068_456255403/\n",
            "  inflating: data_train_short/-220020068_456255403/-220020068_456255403.mp4  \n",
            "   creating: data_train_short/-220020068_456256012/\n",
            "  inflating: data_train_short/-220020068_456256012/-220020068_456256012.mp4  \n",
            "   creating: data_train_short/-220020068_456249716/\n",
            "  inflating: data_train_short/-220020068_456249716/-220020068_456249716.mp4  \n",
            "   creating: data_train_short/-220020068_456255389/\n",
            "  inflating: data_train_short/-220020068_456255389/-220020068_456255389.mp4  \n",
            "   creating: data_train_short/-220020068_456257141/\n",
            "  inflating: data_train_short/-220020068_456257141/-220020068_456257141.mp4  \n",
            "   creating: data_train_short/-220020068_456241851/\n",
            "  inflating: data_train_short/-220020068_456241851/-220020068_456241851.mp4  \n",
            "   creating: data_train_short/-220020068_456256571/\n",
            "  inflating: data_train_short/-220020068_456256571/-220020068_456256571.mp4  \n",
            "   creating: data_train_short/-220020068_456256019/\n",
            "  inflating: data_train_short/-220020068_456256019/-220020068_456256019.mp4  \n",
            "   creating: data_train_short/-220020068_456249720/\n",
            "  inflating: data_train_short/-220020068_456249720/-220020068_456249720.mp4  \n",
            "   creating: data_train_short/-220020068_456255344/\n",
            "  inflating: data_train_short/-220020068_456255344/-220020068_456255344.mp4  \n",
            "   creating: data_train_short/-220020068_456255405/\n",
            "  inflating: data_train_short/-220020068_456255405/-220020068_456255405.mp4  \n",
            "   creating: data_train_short/-220020068_456255391/\n",
            "  inflating: data_train_short/-220020068_456255391/-220020068_456255391.mp4  \n",
            "   creating: data_train_short/-220020068_456241844/\n",
            "  inflating: data_train_short/-220020068_456241844/-220020068_456241844.mp4  \n",
            "   creating: data_train_short/-220020068_456254282/\n",
            "  inflating: data_train_short/-220020068_456254282/-220020068_456254282.mp4  \n",
            "   creating: data_train_short/-220020068_456239859/\n",
            "  inflating: data_train_short/-220020068_456239859/-220020068_456239859.mp4  \n",
            "   creating: data_train_short/-220020068_456255346/\n",
            "  inflating: data_train_short/-220020068_456255346/-220020068_456255346.mp4  \n",
            "   creating: data_train_short/-220020068_456255392/\n",
            "  inflating: data_train_short/-220020068_456255392/-220020068_456255392.mp4  \n",
            "   creating: data_train_short/-220020068_456241845/\n",
            "  inflating: data_train_short/-220020068_456241845/-220020068_456241845.mp4  \n",
            "   creating: data_train_short/-220020068_456255766/\n",
            "  inflating: data_train_short/-220020068_456255766/-220020068_456255766.mp4  \n",
            "   creating: data_train_short/-220020068_456256003/\n",
            "  inflating: data_train_short/-220020068_456256003/-220020068_456256003.mp4  \n",
            "   creating: data_train_short/-220020068_456255393/\n",
            "  inflating: data_train_short/-220020068_456255393/-220020068_456255393.mp4  \n",
            "   creating: data_train_short/-220020068_456257136/\n",
            "  inflating: data_train_short/-220020068_456257136/-220020068_456257136.mp4  \n",
            "   creating: data_train_short/-220020068_456241846/\n",
            "  inflating: data_train_short/-220020068_456241846/-220020068_456241846.mp4  \n",
            "   creating: data_train_short/-220020068_456255767/\n",
            "  inflating: data_train_short/-220020068_456255767/-220020068_456255767.mp4  \n",
            "   creating: data_train_short/-220020068_456254537/\n",
            "  inflating: data_train_short/-220020068_456254537/-220020068_456254537.mp4  \n",
            "   creating: data_train_short/-220020068_456255394/\n",
            "  inflating: data_train_short/-220020068_456255394/-220020068_456255394.mp4  \n",
            "   creating: data_train_short/-220020068_456255409/\n",
            "  inflating: data_train_short/-220020068_456255409/-220020068_456255409.mp4  \n",
            "   creating: data_train_short/-220020068_456257137/\n",
            "  inflating: data_train_short/-220020068_456257137/-220020068_456257137.mp4  \n",
            "   creating: data_train_short/-220020068_456241847/\n",
            "  inflating: data_train_short/-220020068_456241847/-220020068_456241847.mp4  \n",
            "   creating: data_train_short/-220020068_456255773/\n",
            "  inflating: data_train_short/-220020068_456255773/-220020068_456255773.mp4  \n",
            "   creating: data_train_short/-220020068_456256005/\n",
            "  inflating: data_train_short/-220020068_456256005/-220020068_456256005.mp4  \n",
            "   creating: data_train_short/-220020068_456256868/\n",
            "  inflating: data_train_short/-220020068_456256868/-220020068_456256868.mp4  \n",
            "   creating: data_train_short/-220020068_456255349/\n",
            "  inflating: data_train_short/-220020068_456255349/-220020068_456255349.mp4  \n",
            "   creating: data_train_short/-220020068_456255395/\n",
            "  inflating: data_train_short/-220020068_456255395/-220020068_456255395.mp4  \n",
            "   creating: data_train_short/-220020068_456255410/\n",
            "  inflating: data_train_short/-220020068_456255410/-220020068_456255410.mp4  \n",
            "   creating: data_train_short/-220020068_456255779/\n",
            "  inflating: data_train_short/-220020068_456255779/-220020068_456255779.mp4  \n",
            "   creating: data_train_short/-220020068_456256893/\n",
            "  inflating: data_train_short/-220020068_456256893/-220020068_456256893.mp4  \n",
            "   creating: data_train_short/-220020068_456241682/\n",
            "  inflating: data_train_short/-220020068_456241682/-220020068_456241682.mp4  \n",
            "   creating: data_train_short/-220020068_456255396/\n",
            "  inflating: data_train_short/-220020068_456255396/-220020068_456255396.mp4  \n",
            "   creating: data_train_short/-220020068_456255411/\n",
            "  inflating: data_train_short/-220020068_456255411/-220020068_456255411.mp4  \n",
            "   creating: data_train_short/-220020068_456254614/\n",
            "  inflating: data_train_short/-220020068_456254614/-220020068_456254614.mp4  \n",
            "   creating: data_train_short/-220020068_456241849/\n",
            "  inflating: data_train_short/-220020068_456241849/-220020068_456241849.mp4  \n",
            "   creating: data_train_short/-220020068_456255780/\n",
            "  inflating: data_train_short/-220020068_456255780/-220020068_456255780.mp4  \n",
            "   creating: data_train_short/-220020068_456249667/\n",
            "  inflating: data_train_short/-220020068_456249667/-220020068_456249667.mp4  \n",
            "   creating: data_train_short/-220020068_456253855/\n",
            "  inflating: data_train_short/-220020068_456253855/-220020068_456253855.mp4  \n",
            "   creating: data_train_short/-220020068_456255412/\n",
            "  inflating: data_train_short/-220020068_456255412/-220020068_456255412.mp4  \n",
            "   creating: data_train_short/-220020068_456241850/\n",
            "  inflating: data_train_short/-220020068_456241850/-220020068_456241850.mp4  \n",
            "   creating: data_train_short/-220020068_456253876/\n",
            "  inflating: data_train_short/-220020068_456253876/-220020068_456253876.mp4  \n",
            "   creating: data_train_short/-220020068_456256430/\n",
            "  inflating: data_train_short/-220020068_456256430/-220020068_456256430.mp4  \n",
            "   creating: data_train_short/-220020068_456249692/\n",
            "  inflating: data_train_short/-220020068_456249692/-220020068_456249692.mp4  \n",
            "   creating: data_train_short/-220020068_456255338/\n",
            "  inflating: data_train_short/-220020068_456255338/-220020068_456255338.mp4  \n",
            "   creating: data_train_short/-220020068_456255407/\n",
            "  inflating: data_train_short/-220020068_456255407/-220020068_456255407.mp4  \n",
            "   creating: data_train_short/-220020068_456255399/\n",
            "  inflating: data_train_short/-220020068_456255399/-220020068_456255399.mp4  \n",
            "   creating: data_train_short/-220020068_456249719/\n",
            "  inflating: data_train_short/-220020068_456249719/-220020068_456249719.mp4  \n",
            "   creating: data_train_short/-220020068_456255400/\n",
            "  inflating: data_train_short/-220020068_456255400/-220020068_456255400.mp4  \n",
            "   creating: data_train_short/-220020068_456256446/\n",
            "  inflating: data_train_short/-220020068_456256446/-220020068_456256446.mp4  \n",
            "   creating: data_train_short/-220020068_456255401/\n",
            "  inflating: data_train_short/-220020068_456255401/-220020068_456255401.mp4  \n",
            "   creating: data_train_short/-220020068_456249733/\n",
            "  inflating: data_train_short/-220020068_456249733/-220020068_456249733.mp4  \n",
            "  inflating: data_train_short/labels.json  \n",
            "Archive:  /content/data_test_short.zip\n",
            "   creating: data_test_short/\n",
            "   creating: data_test_short/-220020068_456249220/\n",
            "  inflating: data_test_short/-220020068_456249220/-220020068_456249220.mp4  \n",
            "   creating: data_test_short/-220020068_456249373/\n",
            "  inflating: data_test_short/-220020068_456249373/-220020068_456249373.mp4  \n",
            "   creating: data_test_short/-220020068_456249231/\n",
            "  inflating: data_test_short/-220020068_456249231/-220020068_456249231.mp4  \n",
            "   creating: data_test_short/-220020068_456255339/\n",
            "  inflating: data_test_short/-220020068_456255339/-220020068_456255339.mp4  \n",
            "   creating: data_test_short/-220020068_456249284/\n",
            "  inflating: data_test_short/-220020068_456249284/-220020068_456249284.mp4  \n",
            "   creating: data_test_short/-220020068_456241671/\n",
            "  inflating: data_test_short/-220020068_456241671/-220020068_456241671.mp4  \n",
            "   creating: data_test_short/-220020068_456249192/\n",
            "  inflating: data_test_short/-220020068_456249192/-220020068_456249192.mp4  \n",
            "   creating: data_test_short/-220020068_456249257/\n",
            "  inflating: data_test_short/-220020068_456249257/-220020068_456249257.mp4  \n",
            "   creating: data_test_short/-220020068_456249375/\n",
            "  inflating: data_test_short/-220020068_456249375/-220020068_456249375.mp4  \n",
            "   creating: data_test_short/-220020068_456256475/\n",
            "  inflating: data_test_short/-220020068_456256475/-220020068_456256475.mp4  \n",
            "   creating: data_test_short/-220020068_456249206/\n",
            "  inflating: data_test_short/-220020068_456249206/-220020068_456249206.mp4  \n",
            "   creating: data_test_short/-220020068_456249376/\n",
            "  inflating: data_test_short/-220020068_456249376/-220020068_456249376.mp4  \n",
            "   creating: data_test_short/-220020068_456241758/\n",
            "  inflating: data_test_short/-220020068_456241758/-220020068_456241758.mp4  \n",
            "   creating: data_test_short/-220020068_456249243/\n",
            "  inflating: data_test_short/-220020068_456249243/-220020068_456249243.mp4  \n",
            "   creating: data_test_short/-220020068_456249344/\n",
            "  inflating: data_test_short/-220020068_456249344/-220020068_456249344.mp4  \n",
            "   creating: data_test_short/-220020068_456249716/\n",
            "  inflating: data_test_short/-220020068_456249716/-220020068_456249716.mp4  \n",
            "   creating: data_test_short/-220020068_456249259/\n",
            "  inflating: data_test_short/-220020068_456249259/-220020068_456249259.mp4  \n",
            "   creating: data_test_short/-220020068_456255389/\n",
            "  inflating: data_test_short/-220020068_456255389/-220020068_456255389.mp4  \n",
            "   creating: data_test_short/-220020068_456249720/\n",
            "  inflating: data_test_short/-220020068_456249720/-220020068_456249720.mp4  \n",
            "   creating: data_test_short/-220020068_456249272/\n",
            "  inflating: data_test_short/-220020068_456249272/-220020068_456249272.mp4  \n",
            "   creating: data_test_short/-220020068_456249318/\n",
            "  inflating: data_test_short/-220020068_456249318/-220020068_456249318.mp4  \n",
            "   creating: data_test_short/-220020068_456249222/\n",
            "  inflating: data_test_short/-220020068_456249222/-220020068_456249222.mp4  \n",
            "   creating: data_test_short/-220020068_456249358/\n",
            "  inflating: data_test_short/-220020068_456249358/-220020068_456249358.mp4  \n",
            "   creating: data_test_short/-220020068_456249204/\n",
            "  inflating: data_test_short/-220020068_456249204/-220020068_456249204.mp4  \n",
            "   creating: data_test_short/-220020068_456249309/\n",
            "  inflating: data_test_short/-220020068_456249309/-220020068_456249309.mp4  \n",
            "   creating: data_test_short/-220020068_456255346/\n",
            "  inflating: data_test_short/-220020068_456255346/-220020068_456255346.mp4  \n",
            "   creating: data_test_short/-220020068_456249214/\n",
            "  inflating: data_test_short/-220020068_456249214/-220020068_456249214.mp4  \n",
            "   creating: data_test_short/-220020068_456249275/\n",
            "  inflating: data_test_short/-220020068_456249275/-220020068_456249275.mp4  \n",
            "   creating: data_test_short/-220020068_456255393/\n",
            "  inflating: data_test_short/-220020068_456255393/-220020068_456255393.mp4  \n",
            "   creating: data_test_short/-220020068_456249208/\n",
            "  inflating: data_test_short/-220020068_456249208/-220020068_456249208.mp4  \n",
            "   creating: data_test_short/-220020068_456249368/\n",
            "  inflating: data_test_short/-220020068_456249368/-220020068_456249368.mp4  \n",
            "   creating: data_test_short/-220020068_456257137/\n",
            "  inflating: data_test_short/-220020068_456257137/-220020068_456257137.mp4  \n",
            "   creating: data_test_short/-220020068_456249216/\n",
            "  inflating: data_test_short/-220020068_456249216/-220020068_456249216.mp4  \n",
            "   creating: data_test_short/-220020068_456249350/\n",
            "  inflating: data_test_short/-220020068_456249350/-220020068_456249350.mp4  \n",
            "   creating: data_test_short/-220020068_456255410/\n",
            "  inflating: data_test_short/-220020068_456255410/-220020068_456255410.mp4  \n",
            "   creating: data_test_short/-220020068_456249313/\n",
            "  inflating: data_test_short/-220020068_456249313/-220020068_456249313.mp4  \n",
            "   creating: data_test_short/-220020068_456255411/\n",
            "  inflating: data_test_short/-220020068_456255411/-220020068_456255411.mp4  \n",
            "   creating: data_test_short/-220020068_456249211/\n",
            "  inflating: data_test_short/-220020068_456249211/-220020068_456249211.mp4  \n",
            "   creating: data_test_short/-220020068_456249352/\n",
            "  inflating: data_test_short/-220020068_456249352/-220020068_456249352.mp4  \n",
            "   creating: data_test_short/-220020068_456249219/\n",
            "  inflating: data_test_short/-220020068_456249219/-220020068_456249219.mp4  \n",
            "   creating: data_test_short/-220020068_456249315/\n",
            "  inflating: data_test_short/-220020068_456249315/-220020068_456249315.mp4  \n",
            "   creating: data_test_short/-220020068_456249692/\n",
            "  inflating: data_test_short/-220020068_456249692/-220020068_456249692.mp4  \n",
            "   creating: data_test_short/-220020068_456255338/\n",
            "  inflating: data_test_short/-220020068_456255338/-220020068_456255338.mp4  \n",
            "   creating: data_test_short/-220020068_456255399/\n",
            "  inflating: data_test_short/-220020068_456255399/-220020068_456255399.mp4  \n",
            "   creating: data_test_short/-220020068_456249233/\n",
            "  inflating: data_test_short/-220020068_456249233/-220020068_456249233.mp4  \n",
            "  inflating: data_test_short/labels.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-crf\n",
        "!pip install av"
      ],
      "metadata": {
        "id": "GONAYB3janOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import Wav2Vec2Model, Wav2Vec2Processor\n",
        "from timm import create_model\n",
        "from torchcrf import CRF\n",
        "from torchvision import transforms\n",
        "from torchvision.io import read_video\n",
        "from torch.cuda.amp import autocast\n",
        "from einops import rearrange\n",
        "import numpy as np\n",
        "import librosa\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "g7lhnehlXb8n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IntroDetectionModel(nn.Module):\n",
        "    def __init__(self, num_classes=2, vit_name='vit_base_patch16_224', wav2vec_name='facebook/wav2vec2-base'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vit = create_model(vit_name, pretrained=True, num_classes=0)\n",
        "        self.vit_fc = nn.Linear(self.vit.num_features, 512)\n",
        "\n",
        "        self.wav2vec = Wav2Vec2Model.from_pretrained(wav2vec_name)\n",
        "        self.audio_processor = Wav2Vec2Processor.from_pretrained(wav2vec_name)\n",
        "        self.audio_fc = nn.Linear(768, 512)\n",
        "\n",
        "        self.fusion_fc = nn.Linear(512 * 2, 512)\n",
        "\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=512, nhead=8, dim_feedforward=2048),\n",
        "            num_layers=2\n",
        "        )\n",
        "\n",
        "        self.crf = CRF(num_classes)\n",
        "        self.classifier = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, images, audio_input, attention_mask=None, labels=None):\n",
        "        T, B = images.shape[:2]\n",
        "\n",
        "        if len(images.shape) == 5:\n",
        "            images = images.view(T * B, *images.shape[2:])\n",
        "            audio_input = audio_input.view(T * B, -1)\n",
        "            attention_mask = attention_mask.view(T * B, -1)\n",
        "        with torch.no_grad():\n",
        "            image_features = self.vit(images)\n",
        "        image_features = self.vit_fc(image_features)\n",
        "\n",
        "        audio_out = self.wav2vec(audio_input, attention_mask).last_hidden_state.mean(dim=1)\n",
        "        audio_features = self.audio_fc(audio_out)\n",
        "\n",
        "        image_features = image_features.view(T, B, -1)\n",
        "        audio_features = audio_features.view(T, B, -1)\n",
        "\n",
        "        fused = torch.cat([image_features, audio_features], dim=-1)\n",
        "        features = self.fusion_fc(fused)\n",
        "\n",
        "        time_features = self.transformer(features)\n",
        "\n",
        "        emissions = self.classifier(time_features)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss = -self.crf(emissions, labels, reduction='mean')\n",
        "            return loss, emissions\n",
        "        else:\n",
        "            predicted_tags = self.crf.decode(emissions)\n",
        "            return predicted_tags, emissions\n",
        "\n",
        "    def predict(self, images, audio_input):\n",
        "        tags, _ = self.forward(images, audio_input)\n",
        "        return tags"
      ],
      "metadata": {
        "id": "zitTa173aHdP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = IntroDetectionModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE-4J4PXcG7F",
        "outputId": "f4b2e010-2530-4f04-aa31-28df9a22fc1e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:312: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_params(num):\n",
        "    if num >= 1_000_000:\n",
        "        m = int(num / 1_000_000)\n",
        "        rest = num % 1_000_000\n",
        "        if rest >= 1000:\n",
        "            k = rest // 1000\n",
        "            return f\"{m}M {k}K\"\n",
        "        else:\n",
        "            return f\"{m}M\"\n",
        "    elif num >= 1000:\n",
        "        k = num // 1000\n",
        "        return f\"{k}K\"\n",
        "    else:\n",
        "        return str(num)\n",
        "\n",
        "print(f\"Trainable params: {format_params(sum(p.numel() for p in model.parameters() if p.requires_grad))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO8cVwQUdV3u",
        "outputId": "22b49f82-34d2-4922-ad7c-19a9924bf4c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 187M 788K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frames_and_audio(video_path, fps=1, start=None, duration=None):\n",
        "    kwargs = {}\n",
        "    if start is not None or duration is not None:\n",
        "        kwargs['pts_unit'] = 'sec'\n",
        "        if start is not None:\n",
        "            kwargs['start_pts'] = start\n",
        "        if duration is not None:\n",
        "            kwargs['end_pts'] = start + duration if start is not None else duration\n",
        "\n",
        "    video_tensor, audio_tensor, info = read_video(video_path, **kwargs)\n",
        "\n",
        "    video_fps = info.get('video_fps', 25)\n",
        "    audio_fps = info.get('audio_fps', 48000)\n",
        "    total_frames = video_tensor.shape[0]\n",
        "\n",
        "    if duration is not None:\n",
        "        T = max(1, int(duration))\n",
        "    else:\n",
        "        T = max(1, total_frames // video_fps)\n",
        "\n",
        "    selected_indices = torch.linspace(0, total_frames - 1, T).long()\n",
        "\n",
        "    frames = video_tensor[selected_indices].float() / 255.0\n",
        "    frames = rearrange(frames, 't h w c -> t c h w')\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    frames = transform(frames)\n",
        "\n",
        "    if audio_tensor.numel() == 0:\n",
        "        raise ValueError(\"No audio track in this video\")\n",
        "\n",
        "    audio = audio_tensor.mean(dim=0).numpy().astype(np.float32)\n",
        "    target_sr = 16000\n",
        "\n",
        "    if audio_fps != target_sr:\n",
        "        audio = librosa.resample(audio, orig_sr=audio_fps, target_sr=target_sr)\n",
        "        audio_fps = target_sr\n",
        "\n",
        "    samples_per_second = audio_fps\n",
        "    start_sample = int(start * samples_per_second) if start is not None else 0\n",
        "    end_sample = start_sample + int(duration * samples_per_second) if duration is not None else len(audio)\n",
        "    audio_segment = audio[start_sample:end_sample]\n",
        "\n",
        "    required_samples = T * samples_per_second\n",
        "    if len(audio_segment) < required_samples:\n",
        "        pad_len = required_samples - len(audio_segment)\n",
        "        audio_segment = np.pad(audio_segment, (0, pad_len), mode='constant')\n",
        "\n",
        "    audio_segments = audio_segment[:T * samples_per_second].reshape(T, samples_per_second)\n",
        "    audio_segments = torch.tensor(audio_segments)\n",
        "\n",
        "    return frames, audio_segments, audio_fps\n",
        "\n",
        "def process_audio(audio, sample_rate):\n",
        "    if sample_rate != 16000:\n",
        "        audio = librosa.resample(audio, orig_sr=sample_rate, target_sr=16000)\n",
        "    return audio"
      ],
      "metadata": {
        "id": "J0Yr1pMof37y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"/content/data_train_short/-220020068_456239859/-220020068_456239859.mp4\"\n",
        "frames, audio, sr = extract_frames_and_audio(video_path, start=4, duration=5)\n",
        "audio = process_audio(audio, sr)\n",
        "\n",
        "frames = frames.unsqueeze(1) # (frames, batch, channel, w, h)\n",
        "audio_input = torch.tensor(audio).unsqueeze(1) # (frames, batch, seq_len)\n",
        "\n",
        "attention_mask = torch.ones_like(audio_input).bool()\n",
        "\n",
        "print(\"Аудио:\", audio_input.shape)\n",
        "print(\"Картинки:\", frames.shape)\n",
        "\n",
        "model = IntroDetectionModel().eval()\n",
        "\n",
        "with torch.no_grad(), autocast():\n",
        "    predicted_tags, emissions = model(frames, audio_input, attention_mask)\n",
        "\n",
        "print(\"Предсказанные метки:\", predicted_tags)\n",
        "print(len(predicted_tags), emissions.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqW_RXesgnbp",
        "outputId": "14a92371-bbd8-4819-a863-6d7983a19f5a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-3259960646>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  audio_input = torch.tensor(audio).unsqueeze(1) # (frames, batch, seq_len)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Аудио: torch.Size([5, 1, 16000])\n",
            "Картинки: torch.Size([5, 1, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-3259960646>:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предсказанные метки: [[1, 1, 1, 1, 1]]\n",
            "1 torch.Size([5, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "root_dir = \"/content/data_train_short\"\n",
        "all_items = os.listdir(root_dir)\n",
        "folders = [item for item in all_items if os.path.isdir(os.path.join(root_dir, item))]\n",
        "\n",
        "with open(\"/content/labels_json/train_labels.json\", \"r\") as f:\n",
        "    labels_data = json.load(f)\n",
        "\n",
        "for name in labels_data.keys():\n",
        "    print(labels_data[name]['start'], labels_data[name]['end'])\n",
        "\n",
        "# По 5 секунд, до 3 минут"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wpII68V_uQxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IntroDetectionDataset(Dataset):\n",
        "    def __init__(self, root_dir, labels_path, fps=1, fragment_duration=5, max_total_duration=180):\n",
        "        self.root_dir = root_dir\n",
        "        self.fps = fps\n",
        "        self.fragment_duration = fragment_duration\n",
        "        self.max_total_duration = max_total_duration\n",
        "\n",
        "        all_items = os.listdir(root_dir)\n",
        "        self.folder_names = [item for item in all_items if os.path.isdir(os.path.join(root_dir, item))]\n",
        "\n",
        "        with open(labels_path, \"r\") as f:\n",
        "            self.labels_data = json.load(f)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.folder_names) * (self.max_total_duration // self.fragment_duration)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        folder_idx = idx // (self.max_total_duration // self.fragment_duration)\n",
        "        fragment_idx = idx % (self.max_total_duration // self.fragment_duration)\n",
        "\n",
        "        folder_name = self.folder_names[folder_idx]\n",
        "        video_path = os.path.join(self.root_dir, folder_name, f\"{folder_name}.mp4\")\n",
        "\n",
        "        start_sec = fragment_idx * self.fragment_duration\n",
        "        duration_sec = self.fragment_duration\n",
        "\n",
        "        frames, audio_segments, _ = extract_frames_and_audio(\n",
        "            video_path,\n",
        "            fps=self.fps,\n",
        "            start=start_sec,\n",
        "            duration=duration_sec\n",
        "        )\n",
        "\n",
        "        video_key = f\"{folder_name}.mp4\"\n",
        "\n",
        "        fragment_seconds = list(range(start_sec, start_sec + duration_sec))\n",
        "        labels_list = []\n",
        "\n",
        "        intro_start = self.labels_data[folder_name][\"start\"]\n",
        "        intro_end = self.labels_data[folder_name][\"end\"]\n",
        "\n",
        "        def time_to_sec(time_str):\n",
        "            h, m, s = map(int, time_str.split(\":\"))\n",
        "            return h * 3600 + m * 60 + s\n",
        "\n",
        "        intro_start_sec = time_to_sec(intro_start)\n",
        "        intro_end_sec = time_to_sec(intro_end)\n",
        "\n",
        "        for sec in fragment_seconds:\n",
        "            if intro_start_sec <= sec < intro_end_sec:\n",
        "                labels_list.append(1)\n",
        "            else:\n",
        "                labels_list.append(0)\n",
        "\n",
        "        labels_tensor = torch.tensor(labels_list, dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            \"frames\": frames,\n",
        "            \"audio\": audio_segments,\n",
        "            \"labels\": labels_tensor\n",
        "        }\n",
        "\n",
        "def collate_fn(batch):\n",
        "    frames = torch.stack([b[\"frames\"] for b in batch])\n",
        "    audio = torch.stack([b[\"audio\"] for b in batch])\n",
        "    labels = torch.stack([b[\"labels\"] for b in batch])\n",
        "\n",
        "    frames = frames.transpose(0, 1)\n",
        "    audio = audio.transpose(0, 1)\n",
        "    labels = labels.transpose(0, 1)\n",
        "\n",
        "    return {\n",
        "        \"frames\": frames,\n",
        "        \"audio\": audio,\n",
        "        \"labels\": labels\n",
        "    }"
      ],
      "metadata": {
        "id": "a9ay1uWf1t_o"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = IntroDetectionDataset(\"/content/data_train_short\", \"/content/labels_json/train_labels.json\")\n",
        "loader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn)\n",
        "\n",
        "for batch in loader:\n",
        "    print(\"Фреймы:\", batch['frames'].shape)\n",
        "    print(\"Аудио:\", batch['audio'].shape)\n",
        "    print(\"Метки:\", batch['labels'].shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qUR_7g94cQt",
        "outputId": "8e262edc-6385-4946-976e-1736cb6f04d1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фреймы: torch.Size([5, 2, 3, 224, 224])\n",
            "Аудио: torch.Size([5, 2, 16000])\n",
            "Метки: torch.Size([5, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        frames = batch[\"frames\"].to(device)\n",
        "        audio = batch[\"audio\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        emissions = model(frames, audio, labels=labels)\n",
        "        loss, _ = emissions\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Epoch Loss: {avg_loss:.4f}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = IntroDetectionModel().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "loader = DataLoader(dataset, batch_size=4, collate_fn=collate_fn, shuffle=True)\n",
        "\n",
        "for epoch in range(15):\n",
        "    train(model, loader, optimizer, device)"
      ],
      "metadata": {
        "id": "NRscNv6z41ae"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}