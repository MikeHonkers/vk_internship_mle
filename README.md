# vk_internship_mle

Для решения поставленной задачи мною был разработан следующий пайплайн:

## Пайплайн:

1. Аудиофайлы извлекаются из видео, 1 аудио на 1 секунду. seq_len аудио == 16 000.
2. Извлекаются из видео изображения, 1 кадр на 1 секунду.

Всего в один батч укладываются 5 секунд. По хорошему видео разбивается по 5 секунд и всё просматривается, но я решил брать только первые 3 минуты.
Дальше эти данные кладутся по батчам, и подаются на вход модели.

## Модель:

1. Image encoder -- это ViT-base, туда отправляются изображения и на выходе получаются вектора d=512.
2. Audio encoder -- это Wav2Vec-base, туда отправляются аудио и на выходе получается вектора d=512.
3. Применяется early infusion, вектора склеиваются и подаются на вход в небольшой 2-слойный трансформер. (Альтернатива -- 2 слойный Bi-LSTM).
4. Логиты проходят через CRF слой, который старается штрафовать за нечастую последовательность комбинаций меток. ([ccici] -- это будет штрафоваться)
5. На выходе полаем для каждой секунды предсказанный класс -- контент или интро.

## Как можно улучшить:
1. Модель явно через чур большая, её можно сдистилировать в меньшие размеры, очевидно.
2. Вместо ViT-base взять более современный DINO.
3. Добавить Residuals.
